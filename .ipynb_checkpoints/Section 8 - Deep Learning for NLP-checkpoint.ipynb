{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3060ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a954030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a88b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07fe5271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc773bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a55fa67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d9f6768",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "543d61a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20b55e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d9d19ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e112dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(X,y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f67164c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "699ec9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9df9388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1860cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "058ec2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3e17386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AH\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8,input_dim = 4, activation = 'relu'))\n",
    "model.add(Dense(8,input_dim = 4, activation = 'relu'))\n",
    "model.add(Dense(3,activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a8dc64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 139\n",
      "Trainable params: 139\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5488a770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AH\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      " - 0s - loss: 1.1096 - accuracy: 0.3400\n",
      "Epoch 2/150\n",
      " - 0s - loss: 1.1023 - accuracy: 0.3400\n",
      "Epoch 3/150\n",
      " - 0s - loss: 1.0957 - accuracy: 0.3400\n",
      "Epoch 4/150\n",
      " - 0s - loss: 1.0897 - accuracy: 0.3400\n",
      "Epoch 5/150\n",
      " - 0s - loss: 1.0839 - accuracy: 0.3400\n",
      "Epoch 6/150\n",
      " - 0s - loss: 1.0783 - accuracy: 0.3400\n",
      "Epoch 7/150\n",
      " - 0s - loss: 1.0730 - accuracy: 0.3400\n",
      "Epoch 8/150\n",
      " - 0s - loss: 1.0680 - accuracy: 0.3400\n",
      "Epoch 9/150\n",
      " - 0s - loss: 1.0634 - accuracy: 0.3400\n",
      "Epoch 10/150\n",
      " - 0s - loss: 1.0588 - accuracy: 0.3400\n",
      "Epoch 11/150\n",
      " - 0s - loss: 1.0543 - accuracy: 0.3400\n",
      "Epoch 12/150\n",
      " - 0s - loss: 1.0498 - accuracy: 0.3400\n",
      "Epoch 13/150\n",
      " - 0s - loss: 1.0452 - accuracy: 0.3400\n",
      "Epoch 14/150\n",
      " - 0s - loss: 1.0404 - accuracy: 0.3400\n",
      "Epoch 15/150\n",
      " - 0s - loss: 1.0359 - accuracy: 0.3400\n",
      "Epoch 16/150\n",
      " - 0s - loss: 1.0307 - accuracy: 0.3400\n",
      "Epoch 17/150\n",
      " - 0s - loss: 1.0255 - accuracy: 0.3400\n",
      "Epoch 18/150\n",
      " - 0s - loss: 1.0202 - accuracy: 0.3400\n",
      "Epoch 19/150\n",
      " - 0s - loss: 1.0152 - accuracy: 0.3400\n",
      "Epoch 20/150\n",
      " - 0s - loss: 1.0100 - accuracy: 0.3400\n",
      "Epoch 21/150\n",
      " - 0s - loss: 1.0041 - accuracy: 0.3400\n",
      "Epoch 22/150\n",
      " - 0s - loss: 0.9982 - accuracy: 0.3400\n",
      "Epoch 23/150\n",
      " - 0s - loss: 0.9923 - accuracy: 0.3400\n",
      "Epoch 24/150\n",
      " - 0s - loss: 0.9860 - accuracy: 0.3400\n",
      "Epoch 25/150\n",
      " - 0s - loss: 0.9798 - accuracy: 0.3400\n",
      "Epoch 26/150\n",
      " - 0s - loss: 0.9733 - accuracy: 0.3400\n",
      "Epoch 27/150\n",
      " - 0s - loss: 0.9668 - accuracy: 0.3600\n",
      "Epoch 28/150\n",
      " - 0s - loss: 0.9600 - accuracy: 0.3700\n",
      "Epoch 29/150\n",
      " - 0s - loss: 0.9534 - accuracy: 0.4000\n",
      "Epoch 30/150\n",
      " - 0s - loss: 0.9467 - accuracy: 0.4500\n",
      "Epoch 31/150\n",
      " - 0s - loss: 0.9397 - accuracy: 0.5100\n",
      "Epoch 32/150\n",
      " - 0s - loss: 0.9331 - accuracy: 0.5700\n",
      "Epoch 33/150\n",
      " - 0s - loss: 0.9264 - accuracy: 0.6000\n",
      "Epoch 34/150\n",
      " - 0s - loss: 0.9195 - accuracy: 0.6000\n",
      "Epoch 35/150\n",
      " - 0s - loss: 0.9126 - accuracy: 0.6100\n",
      "Epoch 36/150\n",
      " - 0s - loss: 0.9057 - accuracy: 0.6200\n",
      "Epoch 37/150\n",
      " - 0s - loss: 0.8985 - accuracy: 0.6300\n",
      "Epoch 38/150\n",
      " - 0s - loss: 0.8921 - accuracy: 0.6300\n",
      "Epoch 39/150\n",
      " - 0s - loss: 0.8852 - accuracy: 0.6300\n",
      "Epoch 40/150\n",
      " - 0s - loss: 0.8786 - accuracy: 0.6400\n",
      "Epoch 41/150\n",
      " - 0s - loss: 0.8716 - accuracy: 0.6400\n",
      "Epoch 42/150\n",
      " - 0s - loss: 0.8646 - accuracy: 0.6400\n",
      "Epoch 43/150\n",
      " - 0s - loss: 0.8575 - accuracy: 0.6400\n",
      "Epoch 44/150\n",
      " - 0s - loss: 0.8505 - accuracy: 0.6400\n",
      "Epoch 45/150\n",
      " - 0s - loss: 0.8434 - accuracy: 0.6400\n",
      "Epoch 46/150\n",
      " - 0s - loss: 0.8362 - accuracy: 0.6400\n",
      "Epoch 47/150\n",
      " - 0s - loss: 0.8283 - accuracy: 0.6400\n",
      "Epoch 48/150\n",
      " - 0s - loss: 0.8207 - accuracy: 0.6400\n",
      "Epoch 49/150\n",
      " - 0s - loss: 0.8129 - accuracy: 0.6400\n",
      "Epoch 50/150\n",
      " - 0s - loss: 0.8049 - accuracy: 0.6400\n",
      "Epoch 51/150\n",
      " - 0s - loss: 0.7972 - accuracy: 0.6400\n",
      "Epoch 52/150\n",
      " - 0s - loss: 0.7891 - accuracy: 0.6400\n",
      "Epoch 53/150\n",
      " - 0s - loss: 0.7807 - accuracy: 0.6400\n",
      "Epoch 54/150\n",
      " - 0s - loss: 0.7725 - accuracy: 0.6400\n",
      "Epoch 55/150\n",
      " - 0s - loss: 0.7637 - accuracy: 0.6500\n",
      "Epoch 56/150\n",
      " - 0s - loss: 0.7553 - accuracy: 0.6500\n",
      "Epoch 57/150\n",
      " - 0s - loss: 0.7470 - accuracy: 0.6500\n",
      "Epoch 58/150\n",
      " - 0s - loss: 0.7388 - accuracy: 0.6500\n",
      "Epoch 59/150\n",
      " - 0s - loss: 0.7301 - accuracy: 0.6500\n",
      "Epoch 60/150\n",
      " - 0s - loss: 0.7219 - accuracy: 0.6500\n",
      "Epoch 61/150\n",
      " - 0s - loss: 0.7141 - accuracy: 0.6500\n",
      "Epoch 62/150\n",
      " - 0s - loss: 0.7063 - accuracy: 0.6500\n",
      "Epoch 63/150\n",
      " - 0s - loss: 0.6987 - accuracy: 0.6500\n",
      "Epoch 64/150\n",
      " - 0s - loss: 0.6913 - accuracy: 0.6500\n",
      "Epoch 65/150\n",
      " - 0s - loss: 0.6836 - accuracy: 0.6500\n",
      "Epoch 66/150\n",
      " - 0s - loss: 0.6757 - accuracy: 0.6500\n",
      "Epoch 67/150\n",
      " - 0s - loss: 0.6689 - accuracy: 0.6500\n",
      "Epoch 68/150\n",
      " - 0s - loss: 0.6609 - accuracy: 0.6700\n",
      "Epoch 69/150\n",
      " - 0s - loss: 0.6542 - accuracy: 0.6800\n",
      "Epoch 70/150\n",
      " - 0s - loss: 0.6470 - accuracy: 0.6800\n",
      "Epoch 71/150\n",
      " - 0s - loss: 0.6398 - accuracy: 0.6800\n",
      "Epoch 72/150\n",
      " - 0s - loss: 0.6329 - accuracy: 0.6900\n",
      "Epoch 73/150\n",
      " - 0s - loss: 0.6260 - accuracy: 0.6900\n",
      "Epoch 74/150\n",
      " - 0s - loss: 0.6197 - accuracy: 0.6900\n",
      "Epoch 75/150\n",
      " - 0s - loss: 0.6131 - accuracy: 0.6900\n",
      "Epoch 76/150\n",
      " - 0s - loss: 0.6072 - accuracy: 0.6900\n",
      "Epoch 77/150\n",
      " - 0s - loss: 0.6013 - accuracy: 0.6900\n",
      "Epoch 78/150\n",
      " - 0s - loss: 0.5956 - accuracy: 0.6900\n",
      "Epoch 79/150\n",
      " - 0s - loss: 0.5900 - accuracy: 0.7000\n",
      "Epoch 80/150\n",
      " - 0s - loss: 0.5842 - accuracy: 0.7000\n",
      "Epoch 81/150\n",
      " - 0s - loss: 0.5784 - accuracy: 0.7000\n",
      "Epoch 82/150\n",
      " - 0s - loss: 0.5735 - accuracy: 0.6900\n",
      "Epoch 83/150\n",
      " - 0s - loss: 0.5677 - accuracy: 0.6900\n",
      "Epoch 84/150\n",
      " - 0s - loss: 0.5624 - accuracy: 0.6900\n",
      "Epoch 85/150\n",
      " - 0s - loss: 0.5573 - accuracy: 0.6900\n",
      "Epoch 86/150\n",
      " - 0s - loss: 0.5523 - accuracy: 0.7000\n",
      "Epoch 87/150\n",
      " - 0s - loss: 0.5475 - accuracy: 0.7000\n",
      "Epoch 88/150\n",
      " - 0s - loss: 0.5423 - accuracy: 0.7100\n",
      "Epoch 89/150\n",
      " - 0s - loss: 0.5374 - accuracy: 0.7000\n",
      "Epoch 90/150\n",
      " - 0s - loss: 0.5328 - accuracy: 0.7000\n",
      "Epoch 91/150\n",
      " - 0s - loss: 0.5285 - accuracy: 0.7000\n",
      "Epoch 92/150\n",
      " - 0s - loss: 0.5240 - accuracy: 0.7000\n",
      "Epoch 93/150\n",
      " - 0s - loss: 0.5202 - accuracy: 0.7000\n",
      "Epoch 94/150\n",
      " - 0s - loss: 0.5162 - accuracy: 0.7000\n",
      "Epoch 95/150\n",
      " - 0s - loss: 0.5126 - accuracy: 0.7000\n",
      "Epoch 96/150\n",
      " - 0s - loss: 0.5086 - accuracy: 0.7000\n",
      "Epoch 97/150\n",
      " - 0s - loss: 0.5051 - accuracy: 0.7000\n",
      "Epoch 98/150\n",
      " - 0s - loss: 0.5015 - accuracy: 0.7100\n",
      "Epoch 99/150\n",
      " - 0s - loss: 0.4980 - accuracy: 0.7100\n",
      "Epoch 100/150\n",
      " - 0s - loss: 0.4943 - accuracy: 0.7100\n",
      "Epoch 101/150\n",
      " - 0s - loss: 0.4911 - accuracy: 0.7100\n",
      "Epoch 102/150\n",
      " - 0s - loss: 0.4877 - accuracy: 0.7100\n",
      "Epoch 103/150\n",
      " - 0s - loss: 0.4843 - accuracy: 0.7100\n",
      "Epoch 104/150\n",
      " - 0s - loss: 0.4811 - accuracy: 0.7200\n",
      "Epoch 105/150\n",
      " - 0s - loss: 0.4781 - accuracy: 0.7200\n",
      "Epoch 106/150\n",
      " - 0s - loss: 0.4752 - accuracy: 0.7100\n",
      "Epoch 107/150\n",
      " - 0s - loss: 0.4725 - accuracy: 0.7100\n",
      "Epoch 108/150\n",
      " - 0s - loss: 0.4699 - accuracy: 0.7100\n",
      "Epoch 109/150\n",
      " - 0s - loss: 0.4674 - accuracy: 0.7100\n",
      "Epoch 110/150\n",
      " - 0s - loss: 0.4643 - accuracy: 0.7300\n",
      "Epoch 111/150\n",
      " - 0s - loss: 0.4615 - accuracy: 0.7500\n",
      "Epoch 112/150\n",
      " - 0s - loss: 0.4584 - accuracy: 0.7700\n",
      "Epoch 113/150\n",
      " - 0s - loss: 0.4559 - accuracy: 0.8000\n",
      "Epoch 114/150\n",
      " - 0s - loss: 0.4533 - accuracy: 0.8500\n",
      "Epoch 115/150\n",
      " - 0s - loss: 0.4502 - accuracy: 0.8600\n",
      "Epoch 116/150\n",
      " - 0s - loss: 0.4480 - accuracy: 0.8800\n",
      "Epoch 117/150\n",
      " - 0s - loss: 0.4459 - accuracy: 0.8800\n",
      "Epoch 118/150\n",
      " - 0s - loss: 0.4434 - accuracy: 0.8900\n",
      "Epoch 119/150\n",
      " - 0s - loss: 0.4410 - accuracy: 0.8900\n",
      "Epoch 120/150\n",
      " - 0s - loss: 0.4384 - accuracy: 0.8800\n",
      "Epoch 121/150\n",
      " - 0s - loss: 0.4360 - accuracy: 0.8900\n",
      "Epoch 122/150\n",
      " - 0s - loss: 0.4338 - accuracy: 0.9100\n",
      "Epoch 123/150\n",
      " - 0s - loss: 0.4321 - accuracy: 0.9100\n",
      "Epoch 124/150\n",
      " - 0s - loss: 0.4289 - accuracy: 0.9000\n",
      "Epoch 125/150\n",
      " - 0s - loss: 0.4266 - accuracy: 0.8900\n",
      "Epoch 126/150\n",
      " - 0s - loss: 0.4243 - accuracy: 0.9000\n",
      "Epoch 127/150\n",
      " - 0s - loss: 0.4221 - accuracy: 0.8900\n",
      "Epoch 128/150\n",
      " - 0s - loss: 0.4198 - accuracy: 0.9100\n",
      "Epoch 129/150\n",
      " - 0s - loss: 0.4177 - accuracy: 0.9100\n",
      "Epoch 130/150\n",
      " - 0s - loss: 0.4161 - accuracy: 0.9200\n",
      "Epoch 131/150\n",
      " - 0s - loss: 0.4143 - accuracy: 0.9200\n",
      "Epoch 132/150\n",
      " - 0s - loss: 0.4115 - accuracy: 0.9100\n",
      "Epoch 133/150\n",
      " - 0s - loss: 0.4091 - accuracy: 0.9100\n",
      "Epoch 134/150\n",
      " - 0s - loss: 0.4072 - accuracy: 0.9300\n",
      "Epoch 135/150\n",
      " - 0s - loss: 0.4057 - accuracy: 0.9300\n",
      "Epoch 136/150\n",
      " - 0s - loss: 0.4040 - accuracy: 0.9300\n",
      "Epoch 137/150\n",
      " - 0s - loss: 0.4024 - accuracy: 0.9200\n",
      "Epoch 138/150\n",
      " - 0s - loss: 0.4011 - accuracy: 0.9200\n",
      "Epoch 139/150\n",
      " - 0s - loss: 0.3990 - accuracy: 0.9300\n",
      "Epoch 140/150\n",
      " - 0s - loss: 0.3962 - accuracy: 0.9200\n",
      "Epoch 141/150\n",
      " - 0s - loss: 0.3938 - accuracy: 0.9200\n",
      "Epoch 142/150\n",
      " - 0s - loss: 0.3914 - accuracy: 0.9300\n",
      "Epoch 143/150\n",
      " - 0s - loss: 0.3888 - accuracy: 0.9300\n",
      "Epoch 144/150\n",
      " - 0s - loss: 0.3865 - accuracy: 0.9100\n",
      "Epoch 145/150\n",
      " - 0s - loss: 0.3852 - accuracy: 0.9000\n",
      "Epoch 146/150\n",
      " - 0s - loss: 0.3841 - accuracy: 0.8800\n",
      "Epoch 147/150\n",
      " - 0s - loss: 0.3824 - accuracy: 0.8800\n",
      "Epoch 148/150\n",
      " - 0s - loss: 0.3806 - accuracy: 0.8800\n",
      "Epoch 149/150\n",
      " - 0s - loss: 0.3788 - accuracy: 0.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/150\n",
      " - 0s - loss: 0.3767 - accuracy: 0.8900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x177f35c82c8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train, y_train, epochs = 150, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a04c486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 2, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 2, 0,\n",
       "       0, 1, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict_classes(scaled_X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69c99f8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0, 1, 2, 2, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "404258d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb071cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.73      0.85        15\n",
      "           2       0.80      1.00      0.89        16\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        50\n",
      "   macro avg       0.93      0.91      0.91        50\n",
      "weighted avg       0.94      0.92      0.92        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis = 1), predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8606672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test.argmax(axis = 1), predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c52c8eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  0  0]\n",
      " [ 0 11  4]\n",
      " [ 0  0 16]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test.argmax(axis = 1), predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e227f801",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('myfirstmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "106d9ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "076707b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('myfirstmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9404980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9735632b",
   "metadata": {},
   "source": [
    "### RNN  - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0edaadde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    with open(filepath) as f:\n",
    "        str_text = f.read()\n",
    "        \n",
    "    return str_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f3f3760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_file(r'./UPDATED_NLP_COURSE/06-Deep-Learning/melville-moby_dick.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e5e377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba5ef647",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aace369",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = 1198623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f31d0a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_punc(doc_text):\n",
    "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca5192af",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = read_file(r'./UPDATED_NLP_COURSE/06-Deep-Learning/moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eef952f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = separate_punc(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00c5fcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11394"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d06f097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in 25 words to the network as input, the network predict word #26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9b0d644",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 25 + 1\n",
    "\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len, len(tokens)):\n",
    "    seq = tokens[i - train_len : i]\n",
    "    #append 25 words into list\n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3227525f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57e2cbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f0ec330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24852c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1750bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41b9d450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[964,\n",
       " 14,\n",
       " 265,\n",
       " 51,\n",
       " 263,\n",
       " 416,\n",
       " 87,\n",
       " 222,\n",
       " 129,\n",
       " 111,\n",
       " 962,\n",
       " 262,\n",
       " 50,\n",
       " 43,\n",
       " 37,\n",
       " 321,\n",
       " 7,\n",
       " 23,\n",
       " 555,\n",
       " 3,\n",
       " 150,\n",
       " 261,\n",
       " 6,\n",
       " 2704,\n",
       " 14,\n",
       " 24]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4f012ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14,\n",
       " 265,\n",
       " 51,\n",
       " 263,\n",
       " 416,\n",
       " 87,\n",
       " 222,\n",
       " 129,\n",
       " 111,\n",
       " 962,\n",
       " 262,\n",
       " 50,\n",
       " 43,\n",
       " 37,\n",
       " 321,\n",
       " 7,\n",
       " 23,\n",
       " 555,\n",
       " 3,\n",
       " 150,\n",
       " 261,\n",
       " 6,\n",
       " 2704,\n",
       " 14,\n",
       " 24,\n",
       " 965]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb549f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'the',\n",
       " 2: 'a',\n",
       " 3: 'and',\n",
       " 4: 'of',\n",
       " 5: 'i',\n",
       " 6: 'to',\n",
       " 7: 'in',\n",
       " 8: 'it',\n",
       " 9: 'that',\n",
       " 10: 'he',\n",
       " 11: 'his',\n",
       " 12: 'was',\n",
       " 13: 'but',\n",
       " 14: 'me',\n",
       " 15: 'with',\n",
       " 16: 'as',\n",
       " 17: 'you',\n",
       " 18: 'this',\n",
       " 19: 'at',\n",
       " 20: 'is',\n",
       " 21: 'all',\n",
       " 22: 'for',\n",
       " 23: 'my',\n",
       " 24: 'on',\n",
       " 25: 'be',\n",
       " 26: \"'s\",\n",
       " 27: 'not',\n",
       " 28: 'from',\n",
       " 29: 'there',\n",
       " 30: 'one',\n",
       " 31: 'up',\n",
       " 32: 'what',\n",
       " 33: 'him',\n",
       " 34: 'so',\n",
       " 35: 'bed',\n",
       " 36: 'now',\n",
       " 37: 'no',\n",
       " 38: 'about',\n",
       " 39: 'into',\n",
       " 40: 'by',\n",
       " 41: 'were',\n",
       " 42: 'out',\n",
       " 43: 'or',\n",
       " 44: 'harpooneer',\n",
       " 45: 'had',\n",
       " 46: 'then',\n",
       " 47: 'have',\n",
       " 48: 'an',\n",
       " 49: 'upon',\n",
       " 50: 'little',\n",
       " 51: 'some',\n",
       " 52: 'old',\n",
       " 53: 'like',\n",
       " 54: 'if',\n",
       " 55: 'they',\n",
       " 56: 'would',\n",
       " 57: 'do',\n",
       " 58: 'over',\n",
       " 59: 'landlord',\n",
       " 60: 'thought',\n",
       " 61: 'room',\n",
       " 62: 'when',\n",
       " 63: 'could',\n",
       " 64: 'here',\n",
       " 65: 'head',\n",
       " 66: \"n't\",\n",
       " 67: 'night',\n",
       " 68: 'such',\n",
       " 69: 'which',\n",
       " 70: 'man',\n",
       " 71: 'did',\n",
       " 72: 'sea',\n",
       " 73: 'though',\n",
       " 74: 'time',\n",
       " 75: 'other',\n",
       " 76: 'very',\n",
       " 77: 'go',\n",
       " 78: 'these',\n",
       " 79: 'more',\n",
       " 80: 'first',\n",
       " 81: 'sort',\n",
       " 82: 'said',\n",
       " 83: 'last',\n",
       " 84: 'down',\n",
       " 85: 'most',\n",
       " 86: 'been',\n",
       " 87: 'never',\n",
       " 88: 'see',\n",
       " 89: 'your',\n",
       " 90: 'them',\n",
       " 91: 'must',\n",
       " 92: 'tell',\n",
       " 93: 'much',\n",
       " 94: 'good',\n",
       " 95: 'off',\n",
       " 96: 'myself',\n",
       " 97: 'are',\n",
       " 98: 'yet',\n",
       " 99: 'sleep',\n",
       " 100: 'who',\n",
       " 101: 'seemed',\n",
       " 102: 'light',\n",
       " 103: 'way',\n",
       " 104: 'their',\n",
       " 105: 'just',\n",
       " 106: 'being',\n",
       " 107: 'than',\n",
       " 108: 'place',\n",
       " 109: 'queequeg',\n",
       " 110: 'great',\n",
       " 111: 'long',\n",
       " 112: 'before',\n",
       " 113: 'get',\n",
       " 114: 'round',\n",
       " 115: 'where',\n",
       " 116: 'still',\n",
       " 117: 'any',\n",
       " 118: 'too',\n",
       " 119: 'only',\n",
       " 120: 'door',\n",
       " 121: 'can',\n",
       " 122: 'himself',\n",
       " 123: 'heads',\n",
       " 124: 'come',\n",
       " 125: 'ever',\n",
       " 126: 'two',\n",
       " 127: 'enough',\n",
       " 128: 'made',\n",
       " 129: 'how',\n",
       " 130: 'hand',\n",
       " 131: 'same',\n",
       " 132: 'looking',\n",
       " 133: 'something',\n",
       " 134: 'may',\n",
       " 135: \"'\",\n",
       " 136: 'almost',\n",
       " 137: 'say',\n",
       " 138: 'should',\n",
       " 139: 'side',\n",
       " 140: 'why',\n",
       " 141: 'own',\n",
       " 142: 'we',\n",
       " 143: 'new',\n",
       " 144: 'again',\n",
       " 145: 'came',\n",
       " 146: 'arm',\n",
       " 147: 'house',\n",
       " 148: 'away',\n",
       " 149: 'might',\n",
       " 150: 'nothing',\n",
       " 151: 'take',\n",
       " 152: 'towards',\n",
       " 153: 'water',\n",
       " 154: 'will',\n",
       " 155: 'under',\n",
       " 156: 'going',\n",
       " 157: 'rather',\n",
       " 158: 'make',\n",
       " 159: 'whale',\n",
       " 160: 'stood',\n",
       " 161: 'boots',\n",
       " 162: 'ye',\n",
       " 163: 'back',\n",
       " 164: \"'ll\",\n",
       " 165: 'tomahawk',\n",
       " 166: 'part',\n",
       " 167: 'world',\n",
       " 168: 'soon',\n",
       " 169: 'against',\n",
       " 170: 'those',\n",
       " 171: 'between',\n",
       " 172: 'after',\n",
       " 173: 'whaling',\n",
       " 174: 'lay',\n",
       " 175: 'took',\n",
       " 176: 'half',\n",
       " 177: 'began',\n",
       " 178: 'face',\n",
       " 179: 'streets',\n",
       " 180: 'land',\n",
       " 181: 'better',\n",
       " 182: 'once',\n",
       " 183: 'voyage',\n",
       " 184: 'give',\n",
       " 185: 'well',\n",
       " 186: 'however',\n",
       " 187: 'else',\n",
       " 188: 'heard',\n",
       " 189: 'put',\n",
       " 190: 'stop',\n",
       " 191: 'dark',\n",
       " 192: 'went',\n",
       " 193: 'black',\n",
       " 194: 'window',\n",
       " 195: 'cannibal',\n",
       " 196: 'fire',\n",
       " 197: 'every',\n",
       " 198: 'ship',\n",
       " 199: '?--',\n",
       " 200: 'town',\n",
       " 201: 'stand',\n",
       " 202: 'strange',\n",
       " 203: 'without',\n",
       " 204: 'feet',\n",
       " 205: 'whether',\n",
       " 206: 'because',\n",
       " 207: 'eyes',\n",
       " 208: 'think',\n",
       " 209: 'thinks',\n",
       " 210: 'idea',\n",
       " 211: 'bag',\n",
       " 212: 'nantucket',\n",
       " 213: 'late',\n",
       " 214: 'cold',\n",
       " 215: 'our',\n",
       " 216: 'found',\n",
       " 217: 'full',\n",
       " 218: 'morning',\n",
       " 219: 'sleeping',\n",
       " 220: 'feeling',\n",
       " 221: 'got',\n",
       " 222: 'mind',\n",
       " 223: 'her',\n",
       " 224: 'right',\n",
       " 225: 'its',\n",
       " 226: 'look',\n",
       " 227: 'south',\n",
       " 228: 'does',\n",
       " 229: 'let',\n",
       " 230: 'set',\n",
       " 231: 'yourself',\n",
       " 232: 'image',\n",
       " 233: 'saw',\n",
       " 234: 'am',\n",
       " 235: 'besides',\n",
       " 236: 'sailor',\n",
       " 237: 'seas',\n",
       " 238: 'rolled',\n",
       " 239: 'till',\n",
       " 240: 'day',\n",
       " 241: 'sign',\n",
       " 242: 'looked',\n",
       " 243: 'hard',\n",
       " 244: 'moment',\n",
       " 245: 'corner',\n",
       " 246: 'entry',\n",
       " 247: '.--',\n",
       " 248: 'four',\n",
       " 249: 'wall',\n",
       " 250: 'savage',\n",
       " 251: 'table',\n",
       " 252: 'indeed',\n",
       " 253: 'bench',\n",
       " 254: 'chest',\n",
       " 255: 'while',\n",
       " 256: 'stranger',\n",
       " 257: 'possible',\n",
       " 258: 'floor',\n",
       " 259: 'squares',\n",
       " 260: 'hat',\n",
       " 261: 'particular',\n",
       " 262: 'having',\n",
       " 263: 'years',\n",
       " 264: 'harpoon',\n",
       " 265: 'ishmael',\n",
       " 266: 'whenever',\n",
       " 267: 'mouth',\n",
       " 268: 'coffin',\n",
       " 269: 'high',\n",
       " 270: 'knew',\n",
       " 271: 'men',\n",
       " 272: 'hours',\n",
       " 273: 'green',\n",
       " 274: 'bit',\n",
       " 275: 'within',\n",
       " 276: 'picture',\n",
       " 277: 'told',\n",
       " 278: 'story',\n",
       " 279: 'mean',\n",
       " 280: 'thing',\n",
       " 281: ',--',\n",
       " 282: 'speak',\n",
       " 283: 'order',\n",
       " 284: 'making',\n",
       " 285: 'even',\n",
       " 286: 'perhaps',\n",
       " 287: 'things',\n",
       " 288: 'answer',\n",
       " 289: 'parts',\n",
       " 290: 'wild',\n",
       " 291: 'reason',\n",
       " 292: 'young',\n",
       " 293: 'craft',\n",
       " 294: 'business',\n",
       " 295: 'dead',\n",
       " 296: 'another',\n",
       " 297: 'middle',\n",
       " 298: 'sure',\n",
       " 299: 'candle',\n",
       " 300: 'presently',\n",
       " 301: 'low',\n",
       " 302: 'turned',\n",
       " 303: 'teeth',\n",
       " 304: 'dim',\n",
       " 305: 'euroclydon',\n",
       " 306: 'kept',\n",
       " 307: 'glass',\n",
       " 308: 'afterwards',\n",
       " 309: 'large',\n",
       " 310: 'three',\n",
       " 311: 'through',\n",
       " 312: 'telling',\n",
       " 313: 'getting',\n",
       " 314: 'small',\n",
       " 315: 'next',\n",
       " 316: 'seeing',\n",
       " 317: 'sell',\n",
       " 318: 'felt',\n",
       " 319: 'sun',\n",
       " 320: 'e',\n",
       " 321: 'money',\n",
       " 322: 'sail',\n",
       " 323: 'especially',\n",
       " 324: 'street',\n",
       " 325: 'city',\n",
       " 326: 'few',\n",
       " 327: 'previous',\n",
       " 328: 'sight',\n",
       " 329: 'days',\n",
       " 330: 'straight',\n",
       " 331: 'nigh',\n",
       " 332: 'legs',\n",
       " 333: 'try',\n",
       " 334: 'yes',\n",
       " 335: 'unless',\n",
       " 336: 'poor',\n",
       " 337: 'coat',\n",
       " 338: 'passenger',\n",
       " 339: ';--',\n",
       " 340: 'taking',\n",
       " 341: 'true',\n",
       " 342: 'ai',\n",
       " 343: 'always',\n",
       " 344: 'us',\n",
       " 345: 'really',\n",
       " 346: 'marvellous',\n",
       " 347: 'heaven',\n",
       " 348: 'air',\n",
       " 349: 'far',\n",
       " 350: 'second',\n",
       " 351: 'many',\n",
       " 352: 'has',\n",
       " 353: 'unaccountable',\n",
       " 354: 'grand',\n",
       " 355: 'jolly',\n",
       " 356: 'open',\n",
       " 357: 'shirt',\n",
       " 358: 'cape',\n",
       " 359: 'bedford',\n",
       " 360: 'fine',\n",
       " 361: 'further',\n",
       " 362: 'fish',\n",
       " 363: 'inn',\n",
       " 364: 'ice',\n",
       " 365: 'frost',\n",
       " 366: 'foot',\n",
       " 367: 'wide',\n",
       " 368: 'white',\n",
       " 369: 'tall',\n",
       " 370: 'spouter',\n",
       " 371: 'i.',\n",
       " 372: 'wooden',\n",
       " 373: 'worse',\n",
       " 374: 'death',\n",
       " 375: 'mine',\n",
       " 376: 'lazarus',\n",
       " 377: 'keep',\n",
       " 378: 'along',\n",
       " 379: 'hung',\n",
       " 380: 'throwing',\n",
       " 381: 'centre',\n",
       " 382: 'rest',\n",
       " 383: 'fact',\n",
       " 384: 'hair',\n",
       " 385: 'broken',\n",
       " 386: 'kill',\n",
       " 387: 'chimney',\n",
       " 388: 'fancy',\n",
       " 389: 'bar',\n",
       " 390: 'supper',\n",
       " 391: 'trying',\n",
       " 392: 'dumplings',\n",
       " 393: 'heavens',\n",
       " 394: 'manner',\n",
       " 395: 'devil',\n",
       " 396: 'together',\n",
       " 397: 'seen',\n",
       " 398: 'deal',\n",
       " 399: 'know',\n",
       " 400: 'skin',\n",
       " 401: 'ca',\n",
       " 402: 'shavings',\n",
       " 403: 'peddling',\n",
       " 404: 'sunday',\n",
       " 405: 'counterpane',\n",
       " 406: 'mat',\n",
       " 407: 'christian',\n",
       " 408: 'commenced',\n",
       " 409: 'thinking',\n",
       " 410: 'similar',\n",
       " 411: 'afraid',\n",
       " 412: 'length',\n",
       " 413: 'idol',\n",
       " 414: 'sabbee',\n",
       " 415: 'waking',\n",
       " 416: 'ago',\n",
       " 417: 'find',\n",
       " 418: 'damp',\n",
       " 419: 'soul',\n",
       " 420: 'strong',\n",
       " 421: 'account',\n",
       " 422: 'sword',\n",
       " 423: 'quietly',\n",
       " 424: 'degree',\n",
       " 425: 'left',\n",
       " 426: 'around',\n",
       " 427: 'fixed',\n",
       " 428: 'ships',\n",
       " 429: 'miles',\n",
       " 430: 'country',\n",
       " 431: 'stream',\n",
       " 432: 'lead',\n",
       " 433: 'american',\n",
       " 434: 'artist',\n",
       " 435: 'each',\n",
       " 436: 'goes',\n",
       " 437: 'deep',\n",
       " 438: 'distant',\n",
       " 439: 'winds',\n",
       " 440: 'blue',\n",
       " 441: 'among',\n",
       " 442: 'suddenly',\n",
       " 443: 'feel',\n",
       " 444: 'meaning',\n",
       " 445: 'phantom',\n",
       " 446: 'life',\n",
       " 447: 'passengers',\n",
       " 448: 'nor',\n",
       " 449: 'cook',\n",
       " 450: 'kind',\n",
       " 451: 'quite',\n",
       " 452: 'care',\n",
       " 453: 'board',\n",
       " 454: 'somehow',\n",
       " 455: 'broiled',\n",
       " 456: 'mast',\n",
       " 457: 'sense',\n",
       " 458: 'knowing',\n",
       " 459: 'either',\n",
       " 460: 'passed',\n",
       " 461: 'hands',\n",
       " 462: 'paying',\n",
       " 463: 'pay',\n",
       " 464: 'penny',\n",
       " 465: 'sailors',\n",
       " 466: 'exactly',\n",
       " 467: 'short',\n",
       " 468: 'easy',\n",
       " 469: 'portentous',\n",
       " 470: 'island',\n",
       " 471: 'nameless',\n",
       " 472: 'sounds',\n",
       " 473: 'since',\n",
       " 474: 'snow',\n",
       " 475: 'saturday',\n",
       " 476: 'matter',\n",
       " 477: 'red',\n",
       " 478: 'partly',\n",
       " 479: 'ere',\n",
       " 480: 'became',\n",
       " 481: 'meanwhile',\n",
       " 482: 'pocket',\n",
       " 483: 'darkness',\n",
       " 484: 'harpoons',\n",
       " 485: '\"--',\n",
       " 486: 'watch',\n",
       " 487: 'broad',\n",
       " 488: 'entering',\n",
       " 489: 'ha',\n",
       " 490: 'ashes',\n",
       " 491: 'opened',\n",
       " 492: 'peter',\n",
       " 493: 'name',\n",
       " 494: 'suppose',\n",
       " 495: 'quiet',\n",
       " 496: 'best',\n",
       " 497: 'tempestuous',\n",
       " 498: 'says',\n",
       " 499: 'thou',\n",
       " 500: 'both',\n",
       " 501: 'occurred',\n",
       " 502: 'dives',\n",
       " 503: 'holding',\n",
       " 504: 'frozen',\n",
       " 505: 'plenty',\n",
       " 506: 'altogether',\n",
       " 507: 'plain',\n",
       " 508: 'whom',\n",
       " 509: 'clean',\n",
       " 510: 'human',\n",
       " 511: 'entered',\n",
       " 512: 'wrinkled',\n",
       " 513: 'shelf',\n",
       " 514: 'jonah',\n",
       " 515: 'blanket',\n",
       " 516: \"goin'\",\n",
       " 517: 'bitter',\n",
       " 518: 'sat',\n",
       " 519: 'settle',\n",
       " 520: 'chap',\n",
       " 521: 'help',\n",
       " 522: 'spend',\n",
       " 523: 'landed',\n",
       " 524: 'standing',\n",
       " 525: 'held',\n",
       " 526: 'somewhat',\n",
       " 527: 'sober',\n",
       " 528: 'whole',\n",
       " 529: 'dam',\n",
       " 530: 'brown',\n",
       " 531: 'bulkington',\n",
       " 532: \"o'clock\",\n",
       " 533: 'none',\n",
       " 534: 'coming',\n",
       " 535: \"'ve\",\n",
       " 536: 'wait',\n",
       " 537: 'plane',\n",
       " 538: 'saying',\n",
       " 539: 'grinning',\n",
       " 540: 'placed',\n",
       " 541: 'shouted',\n",
       " 542: 'bedfellow',\n",
       " 543: 'zealand',\n",
       " 544: 'sal',\n",
       " 545: 'wash',\n",
       " 546: 'thrown',\n",
       " 547: 'purplish',\n",
       " 548: 'turn',\n",
       " 549: 'completely',\n",
       " 550: 'fear',\n",
       " 551: 'grego',\n",
       " 552: 'baby',\n",
       " 553: 'slowly',\n",
       " 554: 'civilized',\n",
       " 555: 'purse',\n",
       " 556: 'monkey',\n",
       " 557: 'involuntarily',\n",
       " 558: 'pausing',\n",
       " 559: 'warehouses',\n",
       " 560: 'requires',\n",
       " 561: 'people',\n",
       " 562: 'nearly',\n",
       " 563: 'ocean',\n",
       " 564: 'indian',\n",
       " 565: 'waterward',\n",
       " 566: 'battery',\n",
       " 567: 'noble',\n",
       " 568: 'washed',\n",
       " 569: 'crowds',\n",
       " 570: 'sabbath',\n",
       " 571: 'afternoon',\n",
       " 572: 'thence',\n",
       " 573: 'silent',\n",
       " 574: 'thousands',\n",
       " 575: 'reveries',\n",
       " 576: 'leaning',\n",
       " 577: 'seated',\n",
       " 578: 'bulwarks',\n",
       " 579: 'aloft',\n",
       " 580: 'week',\n",
       " 581: 'plaster',\n",
       " 582: 'gone',\n",
       " 583: 'bound',\n",
       " 584: 'content',\n",
       " 585: 'yonder',\n",
       " 586: 'falling',\n",
       " 587: 'north',\n",
       " 588: 'please',\n",
       " 589: 'ten',\n",
       " 590: 'leaves',\n",
       " 591: 'magic',\n",
       " 592: 'plunged',\n",
       " 593: 'metaphysical',\n",
       " 594: 'chief',\n",
       " 595: 'trunk',\n",
       " 596: 'meadow',\n",
       " 597: 'smoke',\n",
       " 598: 'reaching',\n",
       " 599: 'hill',\n",
       " 600: 'thus',\n",
       " 601: 'pine',\n",
       " 602: 'sighs',\n",
       " 603: 'shepherd',\n",
       " 604: 'june',\n",
       " 605: 'scores',\n",
       " 606: 'thousand',\n",
       " 607: 'silver',\n",
       " 608: 'sadly',\n",
       " 609: 'robust',\n",
       " 610: 'healthy',\n",
       " 611: 'boy',\n",
       " 612: 'crazy',\n",
       " 613: 'hold',\n",
       " 614: 'holy',\n",
       " 615: 'brother',\n",
       " 616: 'ourselves',\n",
       " 617: 'begin',\n",
       " 618: 'grow',\n",
       " 619: 'inferred',\n",
       " 620: 'needs',\n",
       " 621: \"don't\",\n",
       " 622: 'themselves',\n",
       " 623: 'commodore',\n",
       " 624: 'captain',\n",
       " 625: 'glory',\n",
       " 626: 'whatsoever',\n",
       " 627: 'confess',\n",
       " 628: 'officer',\n",
       " 629: 'respectfully',\n",
       " 630: 'horse',\n",
       " 631: 'huge',\n",
       " 632: 'houses',\n",
       " 633: 'forecastle',\n",
       " 634: 'jump',\n",
       " 635: 'spar',\n",
       " 636: 'particularly',\n",
       " 637: 'putting',\n",
       " 638: 'tar',\n",
       " 639: 'schoolmaster',\n",
       " 640: 'boys',\n",
       " 641: 'transition',\n",
       " 642: 'grin',\n",
       " 643: 'bear',\n",
       " 644: 'hunks',\n",
       " 645: 'sweep',\n",
       " 646: 'weighed',\n",
       " 647: 'anything',\n",
       " 648: 'less',\n",
       " 649: 'thump',\n",
       " 650: 'point',\n",
       " 651: 'view',\n",
       " 652: 'single',\n",
       " 653: 'difference',\n",
       " 654: 'paid',\n",
       " 655: 'act',\n",
       " 656: 'uncomfortable',\n",
       " 657: 'compare',\n",
       " 658: 'earthly',\n",
       " 659: 'enter',\n",
       " 660: 'deck',\n",
       " 661: 'quarter',\n",
       " 662: 'leaders',\n",
       " 663: 'smelt',\n",
       " 664: 'fates',\n",
       " 665: 'doubtless',\n",
       " 666: 'formed',\n",
       " 667: 'run',\n",
       " 668: 'stage',\n",
       " 669: 'shabby',\n",
       " 670: 'others',\n",
       " 671: 'circumstances',\n",
       " 672: 'motives',\n",
       " 673: 'various',\n",
       " 674: 'mysterious',\n",
       " 675: 'curiosity',\n",
       " 676: 'tormented',\n",
       " 677: 'everlasting',\n",
       " 678: 'wonder',\n",
       " 679: 'purpose',\n",
       " 680: 'floated',\n",
       " 681: 'stuffed',\n",
       " 682: 'horn',\n",
       " 683: 'arrived',\n",
       " 684: 'offer',\n",
       " 685: 'following',\n",
       " 686: 'embark',\n",
       " 687: 'pleased',\n",
       " 688: 'original',\n",
       " 689: 'stranded',\n",
       " 690: 'leviathan',\n",
       " 691: 'whales',\n",
       " 692: 'nay',\n",
       " 693: 'dismal',\n",
       " 694: 'wherever',\n",
       " 695: 'dreary',\n",
       " 696: 'crossed',\n",
       " 697: 'expensive',\n",
       " 698: 'bright',\n",
       " 699: 'windows',\n",
       " 700: 'packed',\n",
       " 701: 'inches',\n",
       " 702: 'thick',\n",
       " 703: 'hear',\n",
       " 704: 'tinkling',\n",
       " 705: 'glasses',\n",
       " 706: 'blackness',\n",
       " 707: 'moving',\n",
       " 708: 'hour',\n",
       " 709: 'proved',\n",
       " 710: 'meant',\n",
       " 711: 'public',\n",
       " 712: 'box',\n",
       " 713: 'flying',\n",
       " 714: '?\"--',\n",
       " 715: 'trap',\n",
       " 716: 'loud',\n",
       " 717: 'voice',\n",
       " 718: 'sitting',\n",
       " 719: 'beyond',\n",
       " 720: 'negro',\n",
       " 721: 'creaking',\n",
       " 722: 'swinging',\n",
       " 723: 'painting',\n",
       " 724: 'representing',\n",
       " 725: 'connexion',\n",
       " 726: 'itself',\n",
       " 727: 'carted',\n",
       " 728: 'burnt',\n",
       " 729: 'spot',\n",
       " 730: 'queer',\n",
       " 731: 'gable',\n",
       " 732: 'ended',\n",
       " 733: 'sharp',\n",
       " 734: 'wind',\n",
       " 735: 'howling',\n",
       " 736: 'nevertheless',\n",
       " 737: 'called',\n",
       " 738: 'outside',\n",
       " 739: 'passage',\n",
       " 740: 'body',\n",
       " 741: 'curbstone',\n",
       " 742: 'corn',\n",
       " 743: 'pooh',\n",
       " 744: 'northern',\n",
       " 745: 'lights',\n",
       " 746: 'summer',\n",
       " 747: 'lengthwise',\n",
       " 748: 'gods',\n",
       " 749: 'lie',\n",
       " 750: 'study',\n",
       " 751: 'series',\n",
       " 752: 'arrive',\n",
       " 753: 'shadows',\n",
       " 754: 'dint',\n",
       " 755: 'conclusion',\n",
       " 756: 'confounded',\n",
       " 757: 'limber',\n",
       " 758: 'truly',\n",
       " 759: 'drive',\n",
       " 760: 'unimaginable',\n",
       " 761: 'midnight',\n",
       " 762: 'unnatural',\n",
       " 763: 'breaking',\n",
       " 764: 'design',\n",
       " 765: 'opposite',\n",
       " 766: 'monstrous',\n",
       " 767: 'knots',\n",
       " 768: 'vast',\n",
       " 769: 'handle',\n",
       " 770: 'wondered',\n",
       " 771: 'mixed',\n",
       " 772: 'deformed',\n",
       " 773: 'flung',\n",
       " 774: 'iron',\n",
       " 775: 'arched',\n",
       " 776: 'cut',\n",
       " 777: 'times',\n",
       " 778: 'beneath',\n",
       " 779: 'covered',\n",
       " 780: 'gathered',\n",
       " 781: 'stands',\n",
       " 782: 'rude',\n",
       " 783: 'bone',\n",
       " 784: 'abominable',\n",
       " 785: 'measure',\n",
       " 786: 'seamen',\n",
       " 787: 'skrimshander',\n",
       " 788: 'sought',\n",
       " 789: 'added',\n",
       " 790: 'forehead',\n",
       " 791: 'objections',\n",
       " 792: \"'d\",\n",
       " 793: 'used',\n",
       " 794: 'depend',\n",
       " 795: 'decent',\n",
       " 796: 'want',\n",
       " 797: 'ready',\n",
       " 798: 'working',\n",
       " 799: 'space',\n",
       " 800: 'lips',\n",
       " 801: 'fingers',\n",
       " 802: 'fare',\n",
       " 803: 'fellow',\n",
       " 804: 'nightmare',\n",
       " 805: 'nt',\n",
       " 806: 'complexioned',\n",
       " 807: 'eats',\n",
       " 808: \"'em\",\n",
       " 809: 'afore',\n",
       " 810: 'resolved',\n",
       " 811: 'noise',\n",
       " 812: 'offing',\n",
       " 813: 'shaggy',\n",
       " 814: 'woollen',\n",
       " 815: 'stiff',\n",
       " 816: 'labrador',\n",
       " 817: 'wake',\n",
       " 818: 'bad',\n",
       " 819: 'mounted',\n",
       " 820: 'generally',\n",
       " 821: 'shipmates',\n",
       " 822: 'become',\n",
       " 823: 'height',\n",
       " 824: 'seem',\n",
       " 825: 'plan',\n",
       " 826: 'private',\n",
       " 827: 'unknown',\n",
       " 828: 'apartment',\n",
       " 829: 'hammock',\n",
       " 830: 'linen',\n",
       " 831: 'home',\n",
       " 832: 'hole',\n",
       " 833: 'mattress',\n",
       " 834: 'planing',\n",
       " 835: 'knot',\n",
       " 836: 'near',\n",
       " 837: 'sake',\n",
       " 838: 'chair',\n",
       " 839: 'narrow',\n",
       " 840: 'leaving',\n",
       " 841: 'interval',\n",
       " 842: 'met',\n",
       " 843: 'inside',\n",
       " 844: 'violent',\n",
       " 845: 'ones',\n",
       " 846: 'comprehension',\n",
       " 847: 'bird',\n",
       " 848: 'airley',\n",
       " 849: 'airth',\n",
       " 850: 'engaged',\n",
       " 851: 'whittling',\n",
       " 852: 'guess',\n",
       " 853: 'done',\n",
       " 854: 'break',\n",
       " 855: 'broke',\n",
       " 856: 'understand',\n",
       " 857: 'certain',\n",
       " 858: 'demand',\n",
       " 859: 'selling',\n",
       " 860: 'sir',\n",
       " 861: 'string',\n",
       " 862: 'mystery',\n",
       " 863: 'showed',\n",
       " 864: 'dangerous',\n",
       " 865: 'flukes',\n",
       " 866: 'slept',\n",
       " 867: 'big',\n",
       " 868: 'sam',\n",
       " 869: 'lighted',\n",
       " 870: 'wo',\n",
       " 871: 'stairs',\n",
       " 872: 'placing',\n",
       " 873: 'double',\n",
       " 874: 'eyeing',\n",
       " 875: 'belonging',\n",
       " 876: 'papered',\n",
       " 877: 'parcel',\n",
       " 878: 'tried',\n",
       " 879: 'satisfactory',\n",
       " 880: 'concerning',\n",
       " 881: 'edges',\n",
       " 882: 'stuck',\n",
       " 883: 'gave',\n",
       " 884: 'neck',\n",
       " 885: 'sleeves',\n",
       " 886: 'undressed',\n",
       " 887: 'remembering',\n",
       " 888: 'jumped',\n",
       " 889: 'pantaloons',\n",
       " 890: 'blowing',\n",
       " 891: 'doze',\n",
       " 892: 'pretty',\n",
       " 893: 'heavy',\n",
       " 894: 'save',\n",
       " 895: 'infernal',\n",
       " 896: 'peddler',\n",
       " 897: 'yellow',\n",
       " 898: 'colour',\n",
       " 899: 'dreadfully',\n",
       " 900: 'sticking',\n",
       " 901: 'cheeks',\n",
       " 902: 'truth',\n",
       " 903: 'remembered',\n",
       " 904: 'whaleman',\n",
       " 905: 'tattooed',\n",
       " 906: 'concluded',\n",
       " 907: 'lying',\n",
       " 908: 'tanning',\n",
       " 909: 'hot',\n",
       " 910: 'produced',\n",
       " 911: 'beaver',\n",
       " 912: 'singing',\n",
       " 913: 'bolted',\n",
       " 914: 'arms',\n",
       " 915: 'running',\n",
       " 916: 'curious',\n",
       " 917: 'hunch',\n",
       " 918: 'congo',\n",
       " 919: 'ill',\n",
       " 920: 'takes',\n",
       " 921: 'biscuit',\n",
       " 922: 'top',\n",
       " 923: 'lamp',\n",
       " 924: 'succeeded',\n",
       " 925: 'polite',\n",
       " 926: 'guttural',\n",
       " 927: 'pagan',\n",
       " 928: 'spell',\n",
       " 929: 'tobacco',\n",
       " 930: 'grunt',\n",
       " 931: 'whatever',\n",
       " 932: 'ee',\n",
       " 933: 'horrid',\n",
       " 934: 'pipe',\n",
       " 935: 'smoking',\n",
       " 936: 'complied',\n",
       " 937: 'patchwork',\n",
       " 938: 'figure',\n",
       " 939: 'shade',\n",
       " 940: 'quilt',\n",
       " 941: 'hugging',\n",
       " 942: 'sensations',\n",
       " 943: 'explain',\n",
       " 944: 'remember',\n",
       " 945: 'circumstance',\n",
       " 946: 'reality',\n",
       " 947: 'stepmother',\n",
       " 948: 'sixteen',\n",
       " 949: 'abed',\n",
       " 950: 'troubled',\n",
       " 951: 'supernatural',\n",
       " 952: 'ages',\n",
       " 953: 'awful',\n",
       " 954: 'consciousness',\n",
       " 955: 'observing',\n",
       " 956: 'creature',\n",
       " 957: 'dress',\n",
       " 958: 'watching',\n",
       " 959: 'probably',\n",
       " 960: 'toilet',\n",
       " 961: 'wrapped',\n",
       " 962: 'precisely',\n",
       " 963: 'jacket',\n",
       " 964: 'call',\n",
       " 965: 'shore',\n",
       " 966: 'watery',\n",
       " 967: 'driving',\n",
       " 968: 'spleen',\n",
       " 969: 'regulating',\n",
       " 970: 'circulation',\n",
       " 971: 'growing',\n",
       " 972: 'grim',\n",
       " 973: 'drizzly',\n",
       " 974: 'november',\n",
       " 975: 'bringing',\n",
       " 976: 'rear',\n",
       " 977: 'funeral',\n",
       " 978: 'meet',\n",
       " 979: 'hypos',\n",
       " 980: 'upper',\n",
       " 981: 'moral',\n",
       " 982: 'principle',\n",
       " 983: 'prevent',\n",
       " 984: 'deliberately',\n",
       " 985: 'stepping',\n",
       " 986: 'methodically',\n",
       " 987: 'knocking',\n",
       " 988: 'hats',\n",
       " 989: 'substitute',\n",
       " 990: 'pistol',\n",
       " 991: 'ball',\n",
       " 992: 'philosophical',\n",
       " 993: 'flourish',\n",
       " 994: 'cato',\n",
       " 995: 'throws',\n",
       " 996: 'surprising',\n",
       " 997: 'cherish',\n",
       " 998: 'feelings',\n",
       " 999: 'insular',\n",
       " 1000: 'manhattoes',\n",
       " ...}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80e94c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39838861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on "
     ]
    }
   ],
   "source": [
    "for i in sequences[0]:\n",
    "    print(tokenizer.index_word[i], end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49fa0268",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "767e6a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2709"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56de05b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4042fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aad3af8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11368, 26)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06a30a0",
   "metadata": {},
   "source": [
    "### RNN  - Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b599da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3792c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "X = sequences[:, : -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afe34150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target\n",
    "y = sequences[: , -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68d98177",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes = vocabulary_size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6b59bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = X.shape[1] #25 word of sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4038a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87f08d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocabulary_size, seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, seq_len, input_length = seq_len))\n",
    "    model.add(LSTM(units = seq_len * 2, return_sequences = True))\n",
    "    model.add(LSTM(units = seq_len * 2))\n",
    "    model.add(Dense(50, activation = 'relu'))\n",
    "    \n",
    "    model.add(Dense(vocabulary_size, activation= 'softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b9b54dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AH\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 25, 25)            67750     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 25, 50)            15200     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2710)              138210    \n",
      "=================================================================\n",
      "Total params: 243,910\n",
      "Trainable params: 243,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocabulary_size + 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c6cc7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "892ad46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AH\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      "11368/11368 [==============================] - 21s 2ms/step - loss: 6.9605 - accuracy: 0.0382 4s\n",
      "Epoch 2/2\n",
      "11368/11368 [==============================] - 11s 974us/step - loss: 6.3748 - accuracy: 0.0527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2b28ae2c8c8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X,y, batch_size = 128, epochs = 2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3ed97f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "model.save('my_mobyic_model.h5')\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('my_simpletokenizer', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6774fd75",
   "metadata": {},
   "source": [
    "### RNN  - Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b5a67f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd7b0eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    \n",
    "    output = []\n",
    "    input_text = seed_text\n",
    "    \n",
    "    for i in range(num_gen_words):\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text][0])\n",
    "        print(encoded_text)\n",
    "        \n",
    "#         pad_encoded = pad_sequences([encoded_text], maxlen = seq_len, truncating = 'pre')\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "\n",
    "        pred_word_ind = model.predict_classes(pad_encoded, verbose = 0)[0]\n",
    "        \n",
    "        pre_word  = tokenizer.index_word[pred_word_ind]\n",
    "        \n",
    "        input_text += ' '+pred_word\n",
    "        \n",
    "        output_text.append(pred_word)\n",
    "        \n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a7ce69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    '''\n",
    "    INPUTS:\n",
    "    model : model that was trained on text data\n",
    "    tokenizer : tokenizer that was fit on text data\n",
    "    seq_len : length of training sequence\n",
    "    seed_text : raw string text to serve as the seed\n",
    "    num_gen_words : number of words to be generated by model\n",
    "    '''\n",
    "    \n",
    "    # Final Output\n",
    "    output_text = []\n",
    "    \n",
    "    # Intial Seed Sequence\n",
    "    input_text = seed_text\n",
    "    \n",
    "    # Create num_gen_words\n",
    "    for i in range(num_gen_words):\n",
    "        \n",
    "        # Take the input text string and encode it to a sequence\n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        \n",
    "        # Pad sequences to our trained rate (50 words in the video)\n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "        \n",
    "        # Predict Class Probabilities for each word\n",
    "        pred_word_ind = model.predict_classes(pad_encoded, verbose=0)[0]\n",
    "        \n",
    "        # Grab word\n",
    "        pred_word = tokenizer.index_word[pred_word_ind] \n",
    "        \n",
    "        # Update the sequence of input text (shifting one over with the new word)\n",
    "        input_text += ' ' + pred_word\n",
    "        \n",
    "        output_text.append(pred_word)\n",
    "        \n",
    "    # Make it look like a sentence.\n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7211168d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'precisely having little or no money in my purse and nothing particular to interest me on shore i thought i would sail about a little and'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text = ' '.join(text_sequences[10])\n",
    "seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb50c62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"see the devil 's religion did maddened aft it was a word and i 'll say that methinks the white whale unmanageably going to the\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, seq_len, seed_text = seed_text, num_gen_words = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24cdcc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9827bbc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model('./UPDATED_NLP_COURSE/06-Deep-Learning/epochBIG.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9888ee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load(open('./UPDATED_NLP_COURSE/06-Deep-Learning/epochBIG', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80162b8a",
   "metadata": {},
   "source": [
    "### QA Bot  - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "db6b2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2257d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./UPDATED_NLP_COURSE/06-Deep-Learning/train_qa.txt', 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c93d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./UPDATED_NLP_COURSE/06-Deep-Learning/test_qa.txt', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c1da8de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "877bfed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c0d91626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(train_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a67c01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "11b9fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "\n",
    "for story, question, answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fd2386b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2c492c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "48d7ab27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len = len(vocab) + 1\n",
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6db43756",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_story_lens = [len(data[0]) for data in all_data]\n",
    "max_story_len = max(all_story_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "55fa811c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len =  max([len(data[1]) for data in all_data])\n",
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd26c2f",
   "metadata": {},
   "source": [
    "### QA Bot  - Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7122dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b8262fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6f741827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mary': 1,\n",
       " 'daniel': 2,\n",
       " 'took': 3,\n",
       " 'bathroom': 4,\n",
       " 'down': 5,\n",
       " 'bedroom': 6,\n",
       " 'got': 7,\n",
       " 'garden': 8,\n",
       " 'the': 9,\n",
       " 'went': 10,\n",
       " 'travelled': 11,\n",
       " 'put': 12,\n",
       " 'moved': 13,\n",
       " 'milk': 14,\n",
       " 'journeyed': 15,\n",
       " 'left': 16,\n",
       " 'hallway': 17,\n",
       " '?': 18,\n",
       " 'john': 19,\n",
       " 'is': 20,\n",
       " 'in': 21,\n",
       " 'back': 22,\n",
       " 'dropped': 23,\n",
       " 'football': 24,\n",
       " 'office': 25,\n",
       " 'sandra': 26,\n",
       " 'picked': 27,\n",
       " 'up': 28,\n",
       " 'no': 29,\n",
       " 'there': 30,\n",
       " 'to': 31,\n",
       " 'kitchen': 32,\n",
       " 'grabbed': 33,\n",
       " '.': 34,\n",
       " 'apple': 35,\n",
       " 'discarded': 36,\n",
       " 'yes': 37}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "93353053",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "aebb7b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question, answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answers.append(answer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a17979ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "66b34e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq), len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2474ef24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c132645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index = tokenizer.word_index,  max_story_len=max_story_len, max_question_len=max_question_len):\n",
    "    #STORIES\n",
    "    X = []\n",
    "    # QUESTIONS\n",
    "    Xq = []\n",
    "    # Y CORRECT ANSWER (yes/no)\n",
    "    Y = []\n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        #for each story\n",
    "        # [23,14, ....]\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return (pad_sequences(X, maxlen=max_story_len), pad_sequences(Xq, maxlen=max_question_len), np.array(Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "97e59602",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "891a1c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e189c7",
   "metadata": {},
   "source": [
    "### QA Bot  - Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8a4d0d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "98f19cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b5b6615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "35dfedf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len, ))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8e715fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1ea7a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT ENCODER M\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim = vocab_size, output_dim = 64))\n",
    "input_encoder_m.add(Dropout(0.3)) #Turn off certain percantage of nodes\n",
    "\n",
    "# (samples, story_maxlen, embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "986000f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT ENCODER C\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim = vocab_size, output_dim = max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3)) #Turn off certain percantage of nodes\n",
    "\n",
    "# OUTPUT\n",
    "# (samples, story_maxlen, max_question_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2f35661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim = vocab_size, output_dim = 64, input_length = max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "#OUTPUT\n",
    "# (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "07779bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENCODED result <-- ENCODER(INPUT)\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ac966f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dot([input_encoded_m, question_encoded], axes = (2,2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4adbaaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([match, input_encoded_c])\n",
    "reponse = Permute((2,1))(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fe3c48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = concatenate([reponse, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f8857b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "11813a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "21f77c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer) #(samples,vocab_size) # YES/NO 0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "af493b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4f4ff67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_sequence, question], answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "02e8d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f33b07e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_2[1][0]               \n",
      "                                                                 sequential_6[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_6[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bd5671",
   "metadata": {},
   "source": [
    "### QA Bot  - Part 4\n",
    "- Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0c080f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AH\\anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 7s 707us/step - loss: 0.8864 - accuracy: 0.4952 - val_loss: 0.6943 - val_accuracy: 0.5030\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.7024 - accuracy: 0.4972 - val_loss: 0.6944 - val_accuracy: 0.5030\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.6954 - accuracy: 0.5054 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 5s 516us/step - loss: 0.6950 - accuracy: 0.5064 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 5s 514us/step - loss: 0.6946 - accuracy: 0.5009 - val_loss: 0.6937 - val_accuracy: 0.5030\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 5s 495us/step - loss: 0.6945 - accuracy: 0.5077 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 5s 496us/step - loss: 0.6949 - accuracy: 0.4977 - val_loss: 0.6950 - val_accuracy: 0.5030\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 6s 552us/step - loss: 0.6946 - accuracy: 0.5018 - val_loss: 0.6938 - val_accuracy: 0.4970\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 5s 541us/step - loss: 0.6942 - accuracy: 0.4980 - val_loss: 0.6937 - val_accuracy: 0.4770\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 5s 540us/step - loss: 0.6932 - accuracy: 0.5050 - val_loss: 0.6944 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 5s 515us/step - loss: 0.6916 - accuracy: 0.5131 - val_loss: 0.6949 - val_accuracy: 0.4830\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 6s 622us/step - loss: 0.6838 - accuracy: 0.5293 - val_loss: 0.6826 - val_accuracy: 0.5320\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 6s 609us/step - loss: 0.6632 - accuracy: 0.5805 - val_loss: 0.6406 - val_accuracy: 0.6450\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 6s 551us/step - loss: 0.6344 - accuracy: 0.6419 - val_loss: 0.6102 - val_accuracy: 0.6740\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 5s 536us/step - loss: 0.6181 - accuracy: 0.6600 - val_loss: 0.6007 - val_accuracy: 0.6940\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 6s 564us/step - loss: 0.6008 - accuracy: 0.6828 - val_loss: 0.5863 - val_accuracy: 0.7120\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 5s 468us/step - loss: 0.5728 - accuracy: 0.7061 - val_loss: 0.5506 - val_accuracy: 0.7340\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 5s 463us/step - loss: 0.5409 - accuracy: 0.7406 - val_loss: 0.5050 - val_accuracy: 0.7750\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 5s 452us/step - loss: 0.5089 - accuracy: 0.7628 - val_loss: 0.4667 - val_accuracy: 0.7960\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 4s 446us/step - loss: 0.4893 - accuracy: 0.7793 - val_loss: 0.4538 - val_accuracy: 0.7840\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 5s 469us/step - loss: 0.4669 - accuracy: 0.7929 - val_loss: 0.4578 - val_accuracy: 0.7910\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 6s 563us/step - loss: 0.4486 - accuracy: 0.8024 - val_loss: 0.4232 - val_accuracy: 0.8280\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 6s 552us/step - loss: 0.4357 - accuracy: 0.8136 - val_loss: 0.4193 - val_accuracy: 0.8250\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 5s 536us/step - loss: 0.4219 - accuracy: 0.8242 - val_loss: 0.4396 - val_accuracy: 0.8300\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 6s 551us/step - loss: 0.4154 - accuracy: 0.8270 - val_loss: 0.4376 - val_accuracy: 0.8010\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 6s 563us/step - loss: 0.4091 - accuracy: 0.8272 - val_loss: 0.4204 - val_accuracy: 0.8250\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 5s 504us/step - loss: 0.4077 - accuracy: 0.8273 - val_loss: 0.4107 - val_accuracy: 0.8260\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 5s 505us/step - loss: 0.3943 - accuracy: 0.8351 - val_loss: 0.4197 - val_accuracy: 0.8120\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 6s 552us/step - loss: 0.3855 - accuracy: 0.8388 - val_loss: 0.4225 - val_accuracy: 0.8170\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 6s 601us/step - loss: 0.3844 - accuracy: 0.8357 - val_loss: 0.3978 - val_accuracy: 0.8290\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 5s 542us/step - loss: 0.3791 - accuracy: 0.8403 - val_loss: 0.4300 - val_accuracy: 0.8250\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 5s 525us/step - loss: 0.3742 - accuracy: 0.8407 - val_loss: 0.4072 - val_accuracy: 0.8240\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 5s 529us/step - loss: 0.3725 - accuracy: 0.8429 - val_loss: 0.4027 - val_accuracy: 0.8190\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 5s 518us/step - loss: 0.3717 - accuracy: 0.8415 - val_loss: 0.3953 - val_accuracy: 0.8270\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 5s 498us/step - loss: 0.3670 - accuracy: 0.8439 - val_loss: 0.4112 - val_accuracy: 0.8240\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 5s 495us/step - loss: 0.3629 - accuracy: 0.8470 - val_loss: 0.4120 - val_accuracy: 0.8230\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 5s 504us/step - loss: 0.3563 - accuracy: 0.8469 - val_loss: 0.3900 - val_accuracy: 0.8170\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 5s 516us/step - loss: 0.3541 - accuracy: 0.8478 - val_loss: 0.3828 - val_accuracy: 0.8320\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 5s 512us/step - loss: 0.3527 - accuracy: 0.8508 - val_loss: 0.4030 - val_accuracy: 0.8160\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 5s 504us/step - loss: 0.3495 - accuracy: 0.8514 - val_loss: 0.3900 - val_accuracy: 0.8370\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.3469 - accuracy: 0.8533 - val_loss: 0.4111 - val_accuracy: 0.8190\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.3439 - accuracy: 0.8582 - val_loss: 0.4057 - val_accuracy: 0.8260\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 5s 506us/step - loss: 0.3446 - accuracy: 0.8540 - val_loss: 0.4006 - val_accuracy: 0.8190\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.3377 - accuracy: 0.8568 - val_loss: 0.3872 - val_accuracy: 0.8340\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 5s 512us/step - loss: 0.3341 - accuracy: 0.8616 - val_loss: 0.3825 - val_accuracy: 0.8320\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 5s 507us/step - loss: 0.3316 - accuracy: 0.8573 - val_loss: 0.3908 - val_accuracy: 0.8370\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 5s 501us/step - loss: 0.3331 - accuracy: 0.8620 - val_loss: 0.3984 - val_accuracy: 0.8290\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 5s 495us/step - loss: 0.3294 - accuracy: 0.8622 - val_loss: 0.3924 - val_accuracy: 0.8310\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 6s 571us/step - loss: 0.3301 - accuracy: 0.8606 - val_loss: 0.4013 - val_accuracy: 0.8160\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 6s 583us/step - loss: 0.3162 - accuracy: 0.8676 - val_loss: 0.3970 - val_accuracy: 0.8220\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 5s 527us/step - loss: 0.3254 - accuracy: 0.8618 - val_loss: 0.3897 - val_accuracy: 0.8260\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 5s 548us/step - loss: 0.3140 - accuracy: 0.8702 - val_loss: 0.4091 - val_accuracy: 0.8210\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 534us/step - loss: 0.3160 - accuracy: 0.8628 - val_loss: 0.3875 - val_accuracy: 0.8390\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 6s 555us/step - loss: 0.3170 - accuracy: 0.8662 - val_loss: 0.3849 - val_accuracy: 0.8310\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 5s 514us/step - loss: 0.3174 - accuracy: 0.8660 - val_loss: 0.3843 - val_accuracy: 0.8410\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 6s 550us/step - loss: 0.3141 - accuracy: 0.8684 - val_loss: 0.4020 - val_accuracy: 0.8240\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 5s 546us/step - loss: 0.3115 - accuracy: 0.8711 - val_loss: 0.3834 - val_accuracy: 0.8370\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 6s 564us/step - loss: 0.3077 - accuracy: 0.8706 - val_loss: 0.3873 - val_accuracy: 0.8310\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 5s 532us/step - loss: 0.3036 - accuracy: 0.8734 - val_loss: 0.4017 - val_accuracy: 0.8210\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.3049 - accuracy: 0.8719 - val_loss: 0.3941 - val_accuracy: 0.8200\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 0.3092 - accuracy: 0.8715 - val_loss: 0.3960 - val_accuracy: 0.8300\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 5s 497us/step - loss: 0.3070 - accuracy: 0.8712 - val_loss: 0.3836 - val_accuracy: 0.8350\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 5s 491us/step - loss: 0.2973 - accuracy: 0.8711 - val_loss: 0.4105 - val_accuracy: 0.8360\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 5s 500us/step - loss: 0.2981 - accuracy: 0.8754 - val_loss: 0.4004 - val_accuracy: 0.8350\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 5s 492us/step - loss: 0.2972 - accuracy: 0.8772 - val_loss: 0.3919 - val_accuracy: 0.8340\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 5s 492us/step - loss: 0.3004 - accuracy: 0.8740 - val_loss: 0.3897 - val_accuracy: 0.8300\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 5s 496us/step - loss: 0.2982 - accuracy: 0.8744 - val_loss: 0.4068 - val_accuracy: 0.8250\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 5s 497us/step - loss: 0.2970 - accuracy: 0.8753 - val_loss: 0.3921 - val_accuracy: 0.8290\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 5s 494us/step - loss: 0.2885 - accuracy: 0.8782 - val_loss: 0.4152 - val_accuracy: 0.8270\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 5s 505us/step - loss: 0.2888 - accuracy: 0.8806 - val_loss: 0.4054 - val_accuracy: 0.8280\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 5s 498us/step - loss: 0.2874 - accuracy: 0.8816 - val_loss: 0.4002 - val_accuracy: 0.8380\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 5s 527us/step - loss: 0.2891 - accuracy: 0.8796 - val_loss: 0.4353 - val_accuracy: 0.8240\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.2880 - accuracy: 0.8789 - val_loss: 0.4059 - val_accuracy: 0.8300\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 5s 507us/step - loss: 0.2824 - accuracy: 0.8835 - val_loss: 0.3933 - val_accuracy: 0.8330\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 5s 505us/step - loss: 0.2784 - accuracy: 0.8825 - val_loss: 0.4042 - val_accuracy: 0.8310\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 5s 517us/step - loss: 0.2854 - accuracy: 0.8831 - val_loss: 0.4016 - val_accuracy: 0.8300\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 5s 514us/step - loss: 0.2779 - accuracy: 0.8851 - val_loss: 0.4235 - val_accuracy: 0.8230\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 5s 497us/step - loss: 0.2810 - accuracy: 0.8825 - val_loss: 0.4233 - val_accuracy: 0.8260\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 5s 498us/step - loss: 0.2744 - accuracy: 0.8859 - val_loss: 0.4398 - val_accuracy: 0.8230\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.2826 - accuracy: 0.8826 - val_loss: 0.4158 - val_accuracy: 0.8250\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 5s 498us/step - loss: 0.2699 - accuracy: 0.8872 - val_loss: 0.4196 - val_accuracy: 0.8290\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 5s 500us/step - loss: 0.2760 - accuracy: 0.8854 - val_loss: 0.4508 - val_accuracy: 0.8250\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 5s 498us/step - loss: 0.2650 - accuracy: 0.8894 - val_loss: 0.4151 - val_accuracy: 0.8360\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 5s 502us/step - loss: 0.2657 - accuracy: 0.8861 - val_loss: 0.4665 - val_accuracy: 0.8180\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.2625 - accuracy: 0.8891 - val_loss: 0.4477 - val_accuracy: 0.8220\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 5s 506us/step - loss: 0.2693 - accuracy: 0.8889 - val_loss: 0.4129 - val_accuracy: 0.8330\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 5s 505us/step - loss: 0.2631 - accuracy: 0.8926 - val_loss: 0.4414 - val_accuracy: 0.8340\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 6s 556us/step - loss: 0.2621 - accuracy: 0.8913 - val_loss: 0.4551 - val_accuracy: 0.8130\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 5s 500us/step - loss: 0.2573 - accuracy: 0.8897 - val_loss: 0.4298 - val_accuracy: 0.8280\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 5s 542us/step - loss: 0.2622 - accuracy: 0.8930 - val_loss: 0.4469 - val_accuracy: 0.8220\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 5s 520us/step - loss: 0.2609 - accuracy: 0.8954 - val_loss: 0.4214 - val_accuracy: 0.8300\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 5s 517us/step - loss: 0.2586 - accuracy: 0.8937 - val_loss: 0.4265 - val_accuracy: 0.8310\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 0.2494 - accuracy: 0.8947 - val_loss: 0.4360 - val_accuracy: 0.8340\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 5s 502us/step - loss: 0.2564 - accuracy: 0.8944 - val_loss: 0.4541 - val_accuracy: 0.8200\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 5s 506us/step - loss: 0.2506 - accuracy: 0.8989 - val_loss: 0.4646 - val_accuracy: 0.8230\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 5s 513us/step - loss: 0.2596 - accuracy: 0.8907 - val_loss: 0.4664 - val_accuracy: 0.8250\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 5s 505us/step - loss: 0.2476 - accuracy: 0.9000 - val_loss: 0.4562 - val_accuracy: 0.8270\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 5s 510us/step - loss: 0.2449 - accuracy: 0.9010 - val_loss: 0.4469 - val_accuracy: 0.8210\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 5s 505us/step - loss: 0.2445 - accuracy: 0.8994 - val_loss: 0.4549 - val_accuracy: 0.8340\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 0.2486 - accuracy: 0.8960 - val_loss: 0.4501 - val_accuracy: 0.8380\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([inputs_train, queries_train], answers_train, batch_size = 32, epochs = 100, validation_data = ([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f533ad50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2b2ad2e9048>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "497623f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "29aed6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = './UPDATED_NLP_COURSE/06-Deep-Learning/chatbot_120_epochs.h5'\n",
    "# model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "84d55532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "68f2e0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ffacf36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cde90d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04e3e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ab36d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e68706b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.98351675\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d50c03",
   "metadata": {},
   "source": [
    "## Writing Your Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "242ef26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ee2c2e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8ef53595",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "35909496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6a7e855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c2105a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fd6b7b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c8ea33cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.97151124\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f5cd37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c070e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fae6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
